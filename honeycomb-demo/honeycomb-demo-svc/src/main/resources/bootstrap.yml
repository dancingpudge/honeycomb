server:
  port: 8084
  servlet:
    context-path: /honeycomb-demo/

spring:
  profiles:
    active: @environment@
  application:
    name: honeycomb-demo

  cloud:
    nacos:
      #注册中心
      discovery:
        group: demo
      #配置中心
      config:
        group: demo
        #指定yaml格式的配置
        file-extension: yaml

  datasource:
    type: com.alibaba.druid.pool.DruidDataSource
    platform: mysql
    driverClassName: com.mysql.cj.jdbc.Driver
    druid:
      initialSize: 1
      maxActive: 100
      minIdle: 1
      maxWait: 60000
      timeBetweenEvictionRunsMillis: 6000000
      minEvictableIdleTimeMillis: 300000
      MaxEvictableIdleTimeMillis: 6000000
      validationQuery: SELECT 'x'
      testWhileIdle: true
      testOnBorrow: false
      testOnReturn: false
      poolPreparedStatements: true
      maxPoolPreparedStatementPerConnectionSize: 20
      filters: stat

  redis:
    jedis:
      pool:
        max-active: 30
        max-wait: -1
        max-idle: 8
        min-idle: 0
  ###########【Kafka集群】###########
  kafka:
    # 重试次数
    producer:
      # 发送的topic
      retries: 0
      # 应答级别:多少个分区副本备份完成时向生产者发送ack确认(可选0、1、all/-1)
      acks: 1
      # 批量大小
      batch-size: 16384
      # 提交延时
      properties.linger.ms: 0
      # 当生产端积累的消息达到batch-size或接收到消息linger.ms后,生产者就会将消息提交给kafka
      # linger.ms为0表示每接收到一条消息就提交给kafka,这时候batch-size其实就没用了
      # 生产端缓冲区大小
      buffer-memory: 33554432
      # Kafka提供的序列化和反序列化类
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
    ###########【初始化消费者配置】###########
    # 默认的消费组ID
    consumer:
      # 是否自动提交offset
      enable-auto-commit: true
      # 提交offset延时(接收到消息后多久提交offset)
      auto.commit.interval.ms: 1000
      # 批量消费每次最多消费多少条消息
      max-poll-records: 50
      # 当kafka中没有初始offset或offset超出范围时将自动重置offset
      # earliest:重置为分区中最小的offset;
      # latest:重置为分区中最新的offset(消费分区中新产生的数据);
      # none:只要有一个分区不存在已提交的offset,就抛出异常;
      auto-offset-reset: latest
      # Kafka提供的序列化和反序列化类
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      properties:
        # 消费会话超时时间(超过这个时间consumer没有发送心跳,就会触发rebalance操作)
        session.timeout.ms: 120000
        # 消费请求超时时间
        request.timeout.ms: 180000
    listener:
      # 消费端监听的topic不存在时，项目启动会报错(关掉)
      missing-topics-fatal: false
      # 设置批量消费
      #type: batch

#mybatis
mybatis:
  mapper-locations: classpath:mapping/*Mapper.xml

#ribbon的使用
ribbon:
  #是否集成Ribbon
  nacos.enabled: true
  # 等待请求响应的超时时间. 单位：ms
  ReadTimeout: 5000
  # 连接超时时间. 单位：ms
  ConnectTimeout: 1000
  # 是否对所有请求进行失败重试, 设置为 false, 让feign只针对Get请求进行重试.
  OkToRetryOnAllOperations: true
  # 同一个服务实例的重试次数 (excluding the first try)
  MaxAutoRetries: 1
  # 不同服务实例的重试次数(excluding the first server)
  MaxAutoRetriesNextServer: 1

#集成熔断机制
feign:
  hystrix:
    enabled: true

#熔断后数据重试组件开启，每分钟重试1次，隔天的频率减半，需开启定时任务
honeycomb:
  feign.retry:
    #重试缓存方案（目前只支持file，redis非必填）
    storageMode: file
    #制定文件存储路径（一下为默认值，非必填）
    fileDir: honeycomb-feign-retry

#feign调用情况日志追踪
logging:
  level:
    #feign日志以什么级别监控哪个接口
    com.honeycomb.demo2.client.Demo2Client: debug